{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b523e24dd1441ae6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Install",
   "id": "77d895f56ebbbe7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29 peft trl triton\n",
    "!pip install --no-deps cut_cross_entropy unsloth_zoo\n",
    "!pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
    "!pip install --no-deps unsloth\n",
    "!pip install gdown\n",
    "\n",
    "import torch\n",
    "import gdown\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq, TextStreamer\n",
    "from trl import SFTTrainer\n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "id": "86c6008889183d54"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Connect drive",
   "id": "81d9b919a5b5d858"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "id": "3b09937c7324a258"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load data",
   "id": "cfde14a6cdcdcba6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/content/dataset.csv\")\n",
    "\n",
    "df"
   ],
   "id": "d7e3e5ee420147e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Split data",
   "id": "c0bf1db6d52764a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, valid_df = train_test_split(df.head, test_size=0.1, random_state=42)\n",
    "\n",
    "dataset = {\n",
    "    \"train\": Dataset.from_pandas(train_df),\n",
    "    \"validation\": Dataset.from_pandas(valid_df),\n",
    "}\n",
    "\n",
    "print(f\"Training size: {len(dataset['train'])}, Validation size: {len(dataset['validation'])}\")"
   ],
   "id": "2bb38100468dea6c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load model",
   "id": "3c23eb029aa6653c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from huggingface_hub import login\n",
    "\n",
    "max_seq_length = 2048\n",
    "dtype = None\n",
    "load_in_4bit = True\n",
    "\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"vilm/vinallama-2.7b-chat\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 8,\n",
    "    target_modules = [\n",
    "    \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",  # Attention\n",
    "    ],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 2902,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None,\n",
    ")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ],
   "id": "6593e03a9880bfb6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prompt",
   "id": "37f84fdf84d965f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import textwrap\n",
    "\n",
    "def format_poem(example):\n",
    "    theme = example[\"title\"]\n",
    "    content = example[\"content\"].strip()\n",
    "    text = f\"\"\"<|im_start|>system\n",
    "Bạn là một AI thi sĩ chuyên sáng tác thơ lục bát bằng tiếng Việt.\n",
    "Hãy thể hiện cảm xúc tinh tế, sử dụng ngôn từ đẹp, và tuân thủ nghiêm ngặt các quy tắc sau:\n",
    "- Bài thơ có nhiều cặp dòng: một dòng 6 chữ, sau đó là một dòng 8 chữ.\n",
    "- Mỗi dòng phải xuống dòng rõ ràng.\n",
    "- Dòng 6 chữ có đúng 6 từ, dòng 8 chữ có đúng 8 từ.\n",
    "- Không được viết sai nhịp, không viết quá, viết thiếu số chữ.\n",
    "- Vần luật phải tự nhiên, đúng phong cách thơ ca truyền thống Việt Nam.\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "Hãy sáng tác một bài thơ lục bát về chủ đề '{theme}'<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{content}<|im_end|>\n",
    "\"\"\".strip()\n",
    "\n",
    "    return {\"text\": text}\n",
    "\n",
    "# update dataset\n",
    "dataset[\"train\"] = dataset[\"train\"].map(\n",
    "    format_poem,\n",
    "    remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "dataset[\"validation\"] = dataset[\"validation\"].map(\n",
    "    format_poem,\n",
    "    remove_columns=dataset[\"validation\"].column_names\n",
    ")\n",
    "\n",
    "print(dataset[\"train\"][0][\"text\"])\n"
   ],
   "id": "d98c80c8ab3bee3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenizer",
   "id": "f99299c95c0c5570"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def tokenize_function(example):\n",
    "    tokenized = tokenizer(\n",
    "        example[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_seq_length\n",
    "    )\n",
    "\n",
    "    #label\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n"
   ],
   "id": "fa06319465a2b6d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tokenized_datasets = {\n",
    "    \"train\": dataset[\"train\"].map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        remove_columns=[\"text\"]\n",
    "    ),\n",
    "    \"validation\": dataset[\"validation\"].map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        remove_columns=[\"text\"]\n",
    "    )\n",
    "}\n"
   ],
   "id": "82bfae4d4630de3c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data collator",
   "id": "ed8e48cca7b6d90e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=-100,\n",
    "    return_tensors=\"pt\"\n",
    ")\n"
   ],
   "id": "eea80893507c0a07"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "batch = [tokenized_datasets[\"train\"][i] for i in range(2)]\n",
    "\n",
    "collated_batch = data_collator(batch)\n",
    "\n",
    "print(collated_batch.keys())  # ['input_ids', 'attention_mask', 'labels']\n",
    "print(\"Input IDs shape:\", collated_batch[\"input_ids\"].shape)    # torch.Size([2, 2048])\n",
    "print(\"Labels shape:\", collated_batch[\"labels\"].shape)          # torch.Size([2, 2048])"
   ],
   "id": "bd759fa6eb13a611"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train",
   "id": "65901766a81aa02c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/vinallama-checkpoints\",\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    max_steps=10000,\n",
    "    warmup_steps=100,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=not torch.cuda.is_bf16_supported(),\n",
    "    bf16=torch.cuda.is_bf16_supported(),\n",
    "    report_to=[],\n",
    "\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    do_eval=True,\n",
    "\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    save_total_limit=3\n",
    ")\n"
   ],
   "id": "f53088bab6f4c927"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    max_seq_length=max_seq_length,\n",
    "    data_collator=data_collator,\n",
    "    dataset_num_proc=2,\n",
    "    packing=False,\n",
    "    args=training_args\n",
    ")\n"
   ],
   "id": "e0c7d0b7f1c7cee9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "trainer.train(resume_from_checkpoint=\"/content/drive/MyDrive/vinallama-checkpoints/checkpoint-1320\")",
   "id": "93a4ce4cef98afd3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
